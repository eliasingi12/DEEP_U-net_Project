{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_final_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliasingi12/DEEP_U-net_Project/blob/master/Project_final_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LQuwr-8Erh5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl -L -o DRIVE.zip \"https://drive.google.com/uc?export=download&id=1aSJuBxtklXelBJEt-kvG32QQYO1BIQyP\"\n",
        "!curl -L -o STARE.zip \"https://drive.google.com/uc?export=download&id=1Iu0sKvN7oB_ARzn8ZsqNw2k7BmFZ54Aj\"\n",
        "!unzip DRIVE.zip\n",
        "!unzip STARE.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yy3sDWfOr0XD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os  # misc operating system specific operations, e.g., reading directries.\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from docopt import docopt\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Cropping2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dr9q0SWxr5Rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "def read_preproc(img_paths):\n",
        "    img_data = []\n",
        "    for path in img_paths:\n",
        "        image = cv2.imread(path)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        img_data.append(image)\n",
        "    return img_data\n",
        "\n",
        "\n",
        "def list_img_paths(dir, format):\n",
        "    image_paths = []\n",
        "    for (dirpath, dirnames, filenames) in os.walk(dir):\n",
        "        for img in filenames:\n",
        "            if format in img and not img.startswith('.'):\n",
        "                image_paths.append(os.path.join(dirpath, img))\n",
        "    return image_paths\n",
        "\n",
        "\n",
        "def show_images(imgs, grid_size=3):\n",
        "    f, axarr = plt.subplots(grid_size,grid_size, figsize=(15, 15))\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            axarr[i,j].imshow(imgs[i*grid_size+j])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def img2bin(img):\n",
        "    img_new = img.copy() # Make copy instead of changing origianl list\n",
        "    rows, cols = img_new.shape\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            if img_new[row][col]*255 > 10:\n",
        "                img_new[row][col] = 1\n",
        "            else:\n",
        "                img_new[row][col] = 0\n",
        "    return img_new.astype(int)\n",
        "\n",
        "def iou(pred,target):\n",
        "    intersection = pred*target\n",
        "    notTrue = 1 - target\n",
        "    union = target + (notTrue * pred)\n",
        "    return np.sum(intersection)/np.sum(union)\n",
        "\n",
        "\n",
        "def avg_iou(preds,targets):\n",
        "\n",
        "    assert len(preds) == len(targets)\n",
        "    \n",
        "    bin_targets = []\n",
        "    for img in targets:\n",
        "        bin_targets.append(img2bin(img))\n",
        "\n",
        "    bin_preds = []\n",
        "    for img in preds:\n",
        "        bin_preds.append(img2bin(img))\n",
        "\n",
        "    pred_targets = [(bin_preds[i], bin_targets[i]) for i in range(len(bin_preds))]\n",
        "\n",
        "    train_iou = []\n",
        "    for pred, target in pred_targets:\n",
        "        train_iou.append(iou(pred,target))\n",
        "\n",
        "    return sum(train_iou)/len(preds)\n",
        "  \n",
        "  \n",
        "def reshape_normalize(arr_to_reshape):\n",
        "    arr_to_reshape = arr_to_reshape.reshape(arr_to_reshape.shape[0], 512, 512, 1)\n",
        "    arr_to_reshape = arr_to_reshape.astype('float32')\n",
        "    arr_to_reshape /= 255\n",
        "    return arr_to_reshape\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_trnd31Wr_-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unet(height,width,n_ch):\n",
        "    inputs = Input((height,width,n_ch))\n",
        "    \n",
        "    # First set of layers\n",
        "    down1 = Conv2D(64, (3,3), padding='same')(inputs)\n",
        "    down1 = BatchNormalization()(down1)\n",
        "    down1 = Activation('relu')(down1)\n",
        "    down1 = Conv2D(64, (3,3), padding='same')(down1)\n",
        "    down1 = BatchNormalization()(down1)\n",
        "    down1 = Activation('relu')(down1)\n",
        "    down1_pool = MaxPooling2D((2,2))(down1)\n",
        "\n",
        "    # Second set of layers\n",
        "    down2 = Conv2D(128, (3,3), padding='same')(down1_pool)\n",
        "    down2 = BatchNormalization()(down2)\n",
        "    down2 = Activation('relu')(down2)\n",
        "    down2 = Conv2D(128, (3,3), padding='same')(down2)\n",
        "    down2 = BatchNormalization()(down2)\n",
        "    down2 = Activation('relu')(down2)\n",
        "    down2_pool = MaxPooling2D((2,2))(down2)\n",
        "\n",
        "    # Third set of layers\n",
        "    down3 = Conv2D(256, (3,3), padding='same')(down2_pool)\n",
        "    down3 = BatchNormalization()(down3)\n",
        "    down3 = Activation('relu')(down3)\n",
        "    down3 = Conv2D(256, (3,3), padding='same')(down3)\n",
        "    down3 = BatchNormalization()(down3)\n",
        "    down3 = Activation('relu')(down3)\n",
        "    down3_pool = MaxPooling2D((2,2))(down3)\n",
        "\n",
        "    # Fourth set of layers\n",
        "    down4 = Conv2D(512, (3,3), padding='same')(down3_pool)\n",
        "    down4 = BatchNormalization()(down4)\n",
        "    down4 = Activation('relu')(down4)\n",
        "    down4 = Conv2D(512, (3,3), padding='same')(down4)\n",
        "    down4 = BatchNormalization()(down4)\n",
        "    down4 = Activation('relu')(down4)\n",
        "    down4_pool = MaxPooling2D((2,2))(down4)\n",
        "\n",
        "    # Fifth set of layers\n",
        "    mid = Conv2D(1024, (3,3), padding='same')(down4_pool)\n",
        "    mid = BatchNormalization()(mid)\n",
        "    mid = Activation('relu')(mid)\n",
        "    mid = Conv2D(1024, (3,3), padding='same')(mid)\n",
        "    mid = BatchNormalization()(mid)\n",
        "    mid = Activation('relu')(mid)\n",
        "\n",
        "    # First up layers\n",
        "    up4 = UpSampling2D((2,2))(mid)\n",
        "    up4 = concatenate([down4,up4], axis=3)\n",
        "    up4 = Conv2D(512, (3,3), padding='same')(up4)\n",
        "    up4 = BatchNormalization()(up4)\n",
        "    up4 = Activation('relu')(up4)\n",
        "    up4 = Conv2D(512, (3,3), padding='same')(up4)\n",
        "    up4 = BatchNormalization()(up4)\n",
        "    up4 = Activation('relu')(up4)\n",
        "    up4 = Conv2D(512, (3,3), padding='same')(up4)\n",
        "    up4 = BatchNormalization()(up4)\n",
        "    up4 = Activation('relu')(up4)\n",
        "\n",
        "    # Second up layers\n",
        "    up3 = UpSampling2D((2,2))(up4)\n",
        "    up3 = concatenate([down3,up3], axis=3)\n",
        "    up3 = Conv2D(256, (3,3), padding='same')(up3)\n",
        "    up3 = BatchNormalization()(up3)\n",
        "    up3 = Activation('relu')(up3)\n",
        "    up3 = Conv2D(256, (3,3), padding='same')(up3)\n",
        "    up3 = BatchNormalization()(up3)\n",
        "    up3 = Activation('relu')(up3)\n",
        "    up3 = Conv2D(256, (3,3), padding='same')(up3)\n",
        "    up3 = BatchNormalization()(up3)\n",
        "    up3 = Activation('relu')(up3)\n",
        "\n",
        "    # Third up layers\n",
        "    up2 = UpSampling2D((2,2))(up3)\n",
        "    up2 = concatenate([down2,up2], axis=3)\n",
        "    up2 = Conv2D(128, (3,3), padding='same')(up2)\n",
        "    up2 = BatchNormalization()(up2)\n",
        "    up2 = Activation('relu')(up2)\n",
        "    up2 = Conv2D(128, (3,3), padding='same')(up2)\n",
        "    up2 = BatchNormalization()(up2)\n",
        "    up2 = Activation('relu')(up2)\n",
        "    up2 = Conv2D(128, (3,3), padding='same')(up2)\n",
        "    up2 = BatchNormalization()(up2)\n",
        "    up2 = Activation('relu')(up2)\n",
        "\n",
        "    # Fourth up layers\n",
        "    up1 = UpSampling2D((2,2))(up2)\n",
        "    up1 = concatenate([down1,up1], axis=3)\n",
        "    up1 = Conv2D(64, (3,3), padding='same')(up1)\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Activation('relu')(up1)\n",
        "    up1 = Conv2D(64, (3,3), padding='same')(up1)\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Activation('relu')(up1)\n",
        "    up1 = Conv2D(64, (3,3), padding='same')(up1)\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Activation('relu')(up1)\n",
        "\n",
        "    # Output layer\n",
        "    out = Conv2D(1, (1,1), padding='same')(up1)\n",
        "    out = Activation('sigmoid')(out)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=out)\n",
        "\n",
        "    model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtwT8zHMsFfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "#image_paths = []\n",
        "#target_paths = []\n",
        "#test_image_paths = []\n",
        "#test_target_paths = []\n",
        "\n",
        "full_paths = {}\n",
        "full_paths[\"training_imgs\"] = \"DRIVE/training/images\"\n",
        "full_paths[\"targets\"] = \"DRIVE/training/1st_manual_tif\"\n",
        "full_paths[\"testing_imgs\"] = \"DRIVE/test/images/\"\n",
        "full_paths[\"testing_targets\"] = \"DRIVE/test/1st_manual_tif\"\n",
        "full_paths[\"STARE_imgs\"] = \"STARE/stare_images_tif\"\n",
        "full_paths[\"STARE_masks_vk\"] = \"STARE/labels_vk_tif\"\n",
        "\n",
        "# Training set\n",
        "image_paths = list_img_paths(full_paths[\"training_imgs\"], '.tif')\n",
        "image_paths.sort()\n",
        "target_paths = list_img_paths(full_paths[\"targets\"], '.tif')\n",
        "target_paths.sort()\n",
        "\n",
        "# Testing set\n",
        "test_image_paths = list_img_paths(full_paths[\"testing_imgs\"], '.tif')\n",
        "test_image_paths.sort()\n",
        "test_target_paths = list_img_paths(full_paths[\"testing_targets\"], '.tif')\n",
        "test_target_paths.sort()\n",
        "\n",
        "augment = True\n",
        "no_imgs = 4\n",
        "\n",
        "if augment:\n",
        "    print(\"Augmenting...\")\n",
        "\n",
        "    # Change DRIVE set to 90:10 train:test instead of 50:50 and add STARE dataset\n",
        "    image_paths.extend(test_image_paths[:-no_imgs])\n",
        "    test_image_paths = test_image_paths[-no_imgs:]\n",
        "\n",
        "    target_paths.extend(test_target_paths[:-no_imgs])\n",
        "    test_target_paths = test_target_paths[-no_imgs:]\n",
        "\n",
        "    #STARE_imgs = list_img_paths(full_paths[\"STARE_imgs\"], '.tif')\n",
        "    #STARE_imgs.sort()\n",
        "    #STARE_targs = list_img_paths(full_paths[\"STARE_masks_vk\"], '.tif')\n",
        "    #STARE_targs.sort()\n",
        "\n",
        "    #image_paths.extend(STARE_imgs[:-2])\n",
        "    #test_image_paths.extend(STARE_imgs[-2:])\n",
        "\n",
        "    #target_paths.extend(STARE_targs[:-2])\n",
        "    #test_target_paths.extend(STARE_targs[-2:])\n",
        "\n",
        "\n",
        "train_input = read_preproc(image_paths)\n",
        "train_target = read_preproc(target_paths)\n",
        "test_input = read_preproc(test_image_paths)\n",
        "test_target = read_preproc(test_target_paths)\n",
        "\n",
        "plt.imshow(train_input[0], interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "train_input = np.array(train_input)\n",
        "train_target = np.array(train_target)\n",
        "test_input = np.array(test_input)\n",
        "test_target = np.array(test_target)\n",
        "\n",
        "train_input = reshape_normalize(train_input)\n",
        "train_target = reshape_normalize(train_target)\n",
        "test_input = reshape_normalize(test_input)\n",
        "test_target = reshape_normalize(test_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "535pP__XsX5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h, w, ch = train_input[0].shape\n",
        "EPOCHS=100\n",
        "\n",
        "model = unet(h,w,ch)\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_input, train_target, epochs=EPOCHS, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1YdYxBDtplh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training prediction\n",
        "train_pred = []\n",
        "for i in range(40-no_imgs):\n",
        "    train_input_fix = np.expand_dims(train_input[i], axis=0)\n",
        "    train_pred.append(model.predict(train_input_fix))\n",
        "\n",
        "train_pred = np.array(train_pred)\n",
        "#train_pred = train_pred.reshape(train_pred.shape[0], 512, 512) \n",
        "#plt.imshow(train_pred[52], interpolation='nearest')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "# testing prediction\n",
        "test_pred = model.predict(test_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nib6XR-1t0qB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Display Images ###\n",
        "train_target = train_target.reshape(train_target.shape[0], 512, 512)\n",
        "test_target = test_target.reshape(test_target.shape[0], 512, 512)\n",
        "train_pred = train_pred.reshape(train_pred.shape[0], 512, 512) \n",
        "test_pred = test_pred.reshape(test_pred.shape[0], 512, 512) \n",
        "\n",
        "plt.imshow(train_pred[0], interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(train_target[0], interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(test_pred[1], interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(test_target[1], interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "### ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A_Rre8AoRH47",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"train: \")\n",
        "print(avg_iou(train_pred, train_target))\n",
        "\n",
        "print(\"test: \")\n",
        "print(avg_iou(test_pred, test_target))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7nHLR5AzlR8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Non grid IOU images...\n",
        "plt.imshow(img2bin(train_pred[0]), interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(train_target[0]), interpolation='nearest')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(test_pred[1]), interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(test_pred[1]), interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(test_target[1]), interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(test_pred[4]), interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2bin(test_target[4]), interpolation='nearest')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}